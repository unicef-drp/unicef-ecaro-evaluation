{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "upstream = None\n",
    "product = None\n",
    "data_source = 'data/corpora/rdletters/' \n",
    "countries_list = ['ARM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook uses an LLM model to summarize Regional Directors Letters to identify key strengths (well-executed areas) and areas for improvement (sections needing further attention or action). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import unicef_cpe \n",
    "# from unicef_cpe.config import DATA_DIR, OUTPUT_DATA_DIR\n",
    "from unicef_cpe.config import PROJ_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict only to these countries to avoid unexpected costs and long executing times.\n",
    "COUNTRY_CODE_LIST = countries_list\n",
    "\n",
    "COUNTRIES = unicef_cpe.utils.get_ecaro_countries_mapping(priority=False)\n",
    "COUNTRY_CODES = {v:k for k, v in COUNTRIES.items()}\n",
    "MODEL =  'llama3.2:1b'\n",
    "API_TYPE='ollama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upstream_data = {\n",
    "#     'rdletters': (DATA_DIR / 'corpora' / 'rdletters'), \n",
    "#     }\n",
    "\n",
    "# product = OUTPUT_DATA_DIR.joinpath('rd_letters-strengths-improvement_llama.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "source_path =  PROJ_ROOT / Path(data_source)\n",
    "\n",
    "for country in tqdm(COUNTRY_CODE_LIST):\n",
    "    for file_path in source_path.glob(f'{country.lower()}*.*'):\n",
    "    # for file_path in list(Path(source_path).glob(f'{country.lower()}*.*')):     \n",
    "    # for file_path in list(upstream_data['rdletters'].glob(f'{country.lower()}*.*')):\n",
    "        year = int(re.search(r'\\d+', file_path.name).group())\n",
    "        record = {\n",
    "            'country_code': country,\n",
    "            'country': COUNTRIES.get(country),\n",
    "            'file_name': file_path.name,\n",
    "            'file_type': file_path.parent.name,\n",
    "            'year': year,\n",
    "            'text': unicef_cpe.extraction.extract_text_from_file(file_path),\n",
    "        }\n",
    "        if not record['text'].strip():\n",
    "            print(f'{file_path} is empty.')\n",
    "            continue\n",
    "        #print(record)\n",
    "\n",
    "        records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd_letters = pd.DataFrame.from_records(records)\n",
    "df_rd_letters.sort_values(['country','year'], inplace=True)\n",
    "print(df_rd_letters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "list_of_countries = [COUNTRIES.get(country) for country in COUNTRY_CODE_LIST]\n",
    "\n",
    "for country in list_of_countries:\n",
    "    print(country)\n",
    "    country_mask = df_rd_letters['country'] == country\n",
    "    \n",
    "    years = sorted(df_rd_letters[country_mask]['year'].unique())\n",
    "    print(years)\n",
    "    for year in years:\n",
    "        year_mask = df_rd_letters['year'] == year\n",
    "        \n",
    "        try:\n",
    "            # We take only the text from the first section as it is the **context** section\n",
    "            text = df_rd_letters[country_mask & year_mask]['text'].iloc[0]\n",
    "        except IndexError:\n",
    "            # Skip if there's no narrative text for this combination of country and year\n",
    "            print(f\"No narrative text available for {country} in {year}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Summarizing Feedbacks for {country} in {year}\")\n",
    "        #response = unicef_cpe.genai.summarise_acomplishments(text, model=MODEL, api_type=API_TYPE)\n",
    "        #df_list.append(response)\n",
    "#         sections = re.split(r'####', response.strip(), maxsplit=2)\n",
    "#         section_title1 = 'Strengths'  # The first section's title\n",
    "#         section_text1 = sections[1].split('Strengths')[1].strip()\n",
    "#         section_title2 = 'Areas for Improvement'  # The second section's title is always the same\n",
    "#         section_text2 = sections[2].split('Areas for Improvement')[1].strip()\n",
    "\n",
    "#         country_code = COUNTRY_CODES.get(country)\n",
    "#         df_list.append([country_code, country, year, section_title1, section_text1])\n",
    "#         df_list.append([country_code, country, year, section_title2, section_text2])\n",
    "\n",
    "# df_feedback = pd.DataFrame(df_list, columns=['country_code', 'country', 'year', 'feedback_title', 'feedback_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_feedback.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback.to_excel(product['data'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict\n",
    "from typing_extensions import Annotated\n",
    "import json\n",
    "from typing import Dict\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "# Adjusted Schema: Ensure Strengths and Areas_for_Improvement are only Dict[str, str]\n",
    "class EvaluationSummary(BaseModel):\n",
    "    \"\"\"Structured summary of strengths and areas for improvement in a UNICEF evaluation.\"\"\"\n",
    "    Strengths: Dict[str, str] = Field(\n",
    "        ..., description=\"A dictionary where keys are section names and values are concise descriptions of strengths.\"\n",
    "    )\n",
    "    Areas_for_Improvement: Dict[str, str] = Field(\n",
    "        ..., description=\"A dictionary where keys are section names and values are concise descriptions of areas needing improvement.\"\n",
    "    )\n",
    "\n",
    "# Adjusted system message with a stronger instruction\n",
    "system_message = \"\"\"\n",
    "You are a UNICEF expert analyzing a text that reports what was done well and what needs improvement in a program or initiative.\n",
    "\n",
    "### **Instructions**:\n",
    "1. Extract all key points from the text.\n",
    "2. Categorize them into:\n",
    "   - **Strengths**: What was successfully carried out.\n",
    "   - **Areas for Improvement**: What needs further attention or refinement.\n",
    "3. Capture all relevant detailsâ€”do not omit minor but important points.\n",
    "4. **Return only structured JSON** in this format:\n",
    "   ```json\n",
    "   {\n",
    "       \"Strengths\": {\n",
    "           \"Action/Aspect 1\": \"Brief description\",\n",
    "           \"Action/Aspect 2\": \"Brief description\"\n",
    "       },\n",
    "       \"Areas_for_Improvement\": {\n",
    "           \"Action/Aspect 1\": \"Brief description\",\n",
    "           \"Action/Aspect 3\": \"Brief description\"\n",
    "       }\n",
    "   }\n",
    "5.\tDo not include explanations, introductions, or extra text.\n",
    "6.\tEnsure each action/aspect appears only once per category.\n",
    "7.\tExtract and categorize the maximum number of relevant points.\n",
    "\"\"\"\n",
    "# llm = ChatOpenAI(\n",
    "#             model='gpt-3.5-turbo',\n",
    "#             temperature=0.0,\n",
    "#             seed=42\n",
    "#         )\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model='mistral',\n",
    "    temperature=0.0,\n",
    "    seed=42\n",
    ").with_structured_output(EvaluationSummary, method=\"json_schema\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=text),\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.Strengths, response.Areas_for_Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.Strengths), len(response.Areas_for_Improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unicef-ecaro-cpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
