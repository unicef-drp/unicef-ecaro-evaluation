{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: The parameters below are set only for running this notebook independently. \n",
    "# When executing the full Ploomber pipeline, these values will be overridden by the settings in `pipeline.yaml`. \n",
    "# Any modifications made here will not persist when running the pipeline.\n",
    "\n",
    "upstream = None\n",
    "COUNTRY =  'ARM' # Code of the Country\n",
    "product = {'data': f'../data/processed/{COUNTRY}/output-summary-narrative.xlsx'}  # Path to save the final data product (stored under the 'data' key)\n",
    "data_source = 'data/raw/insight-ram-combined-outcomes-outputs-and-end-year-summary-narratives-report'  # Path to the source data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook extracts output narratives from the annual End Year Summary Narratives Report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract narratives from outcomes and outputs\n",
    "## End of the year summaries\n",
    "\n",
    "**Description**\n",
    "Each Outcome and Output have updates every year with the following paragraphs:\n",
    "Headline Statement\n",
    "1. Output Analytical Statement of Progress\n",
    "2. Lessons Learned and Innovations\n",
    "3. Contributions\n",
    "4. Partnerhsips\n",
    "\n",
    "Source data from: **raw/RAM3-combined-outcomes-outputs-and-end-year-summary-narratives-report**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from unicef_cpe.config import PROJ_ROOT\n",
    "import re\n",
    "import unicef_cpe.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict only to the country \n",
    "\n",
    "country_map = {k:v for k,v in utils.get_ecaro_countries_mapping(priority=False).items() if k in COUNTRY}\n",
    "country_code_map = {v:k for k,v in country_map.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = PROJ_ROOT / data_source\n",
    "file_path = [x for x in sorted(Path(source_path).glob('*.csv'))][0]\n",
    "country_programme = '-'.join(file_path.name.split('-')[-3:]).replace('.csv','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for file_path in sorted(Path(source_path).glob('*.csv')):\n",
    "    country, year = file_path.name.split('-')[-5:3]\n",
    "    country_programme = '-'.join(file_path.name.split('-')[-3:]).replace('.csv','')\n",
    "    match = re.search(r'\\d{4}', file_path.name)\n",
    "    if not match:\n",
    "        print(f'Could not find a match in {file_path.name}. Skipping...')\n",
    "        continue\n",
    "    if COUNTRY == country:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['year'] = int(match.group())\n",
    "        df['country_code'] = country\n",
    "        df['country'] = country_map.get(country)\n",
    "        df['country_programme'] = country_programme\n",
    "        df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "print('Shape:', df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Identify which column to keep and which to remove\n",
    "# to_keep = ['country_code', 'country', 'country_programme']\n",
    "# to_remove =[]\n",
    "# for col in df.columns:\n",
    "#     #if the columns has always the same value os safe to remove it\n",
    "#     if df[col].nunique()<=1:\n",
    "#         pass#to_remove.append(col)\n",
    "#     # We are not interested in the indicator as for now\n",
    "#     # elif 'indicator' not in col.lower():\n",
    "#     else:\n",
    "#         to_keep.append(col)\n",
    "# print(len(to_keep),len(to_remove))\n",
    "# print('Shape before:', df.shape)\n",
    "# df = df[to_keep].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.map(utils.clean_text)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print('Shape after:', df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe insight by looking at **PCR_FULL_TEXT** columns:\n",
    "1. **Outcome Statement**\n",
    "   1. **Textbox1** -> Outcome code + name\n",
    "   2. **PCR_FULL_TEXT** -> Outcome Statement\n",
    "   3. **Textbox3** -> Output code + name\n",
    "   4. **Textbox12** -> Output Statement \n",
    "2. **NarrativeTitle**  is empty\n",
    "3.  **Update on the context and situation of children** has only:\n",
    "    1.   **Textbox1**-> **Document Title**\n",
    "    2.   **Textbox9**-> **Text Description**\n",
    "4.  **Major contributions and drivers of results** has only:\n",
    "    1.   **Textbox1**-> **Document Title**\n",
    "    2.   **Textbox9**-> **Text Description**\n",
    "5.  **UN Collaboration and Other Partnerships**  has only:\n",
    "    1.   **Textbox1**-> **Document Title**\n",
    "    2.   **Textbox9**-> **Text Description**\n",
    "6.  **Lessons Learned and Innovations**  has only:\n",
    "    1.   **Textbox1**-> **Document Title**\n",
    "    2.   **Textbox9**-> **Text Description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_columns = ['country_programme', 'year', 'country_code', 'country','section']\n",
    "coars_columns = [ 'coar_title', 'section_description']\n",
    "narrative_columns = ['outcome_code', 'outcome_name', 'outcome_description', 'output_code', 'output_name', 'output_description']\n",
    "indicator_columns = [col for col in df.columns if col.startswith('Indicator_Status')]\n",
    "description_columns = [\n",
    "    'Progress_headline_statement3',\n",
    "    'Progress_headline_statement4',\n",
    "    'Progress_headline_statement7',\n",
    "    'Require_adjustments4',\n",
    "    'Require_adjustments5',\n",
    "    'Details_of_Contribution_Test4',\n",
    "    'Details_of_Contribution_Test5',\n",
    "    'Partnerhsips4',\n",
    "    'Partnerhsips5', \n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_section(row):\n",
    "    # Extract 'Outcome Statement' if it starts the text, otherwise keep the original text\n",
    "    return 'Outcome Statement' if row.startswith('Outcome Statement') else row\n",
    "\n",
    "# Apply the section extraction to create a new 'section' column\n",
    "df['section'] = df['PCR_FULL_TEXT'].apply(extract_section)\n",
    "\n",
    "def process_outcome_and_output(row):\n",
    "    # Process rows where the section is 'Outcome Statement'\n",
    "    if row['section'] == 'Outcome Statement':\n",
    "        try:\n",
    "            # Extract outcome information from Textbox1\n",
    "            outcome = row['Textbox1'].replace('Outcome:', '').strip()\n",
    "            outcome_code, outcome_name = outcome.split(' ', 1)\n",
    "\n",
    "            # Extract outcome description from PCR_FULL_TEXT\n",
    "            outcome_description = row['PCR_FULL_TEXT'].replace('Outcome Statement:', '').strip()\n",
    "\n",
    "            # Extract output information from Textbox3\n",
    "            output = row['Textbox3'].replace('Output:', '').strip()\n",
    "            output_code, output_name = output.split(' ', 1)\n",
    "            \n",
    "            # Output description from PCR_FULL_TEXT\n",
    "            output_description = row['Textbox12'].replace('Output Statement:', '').strip()\n",
    "\n",
    "            return outcome_code, outcome_name, outcome_description, output_code, output_name, output_description, None, None\n",
    "        except (ValueError, AttributeError):\n",
    "            # Handle unexpected format or missing values\n",
    "            return None, None, None, None, None, None, None, None\n",
    "    else:\n",
    "        # For other sections, return the relevant coar_title and section_description\n",
    "        coar_title = row.get('Textbox1', None)\n",
    "        section_description = row.get('Textbox9', None)\n",
    "        return None, None, None, None, None, None, coar_title, section_description\n",
    "\n",
    "# Apply the function row-wise and assign the result to new columns\n",
    "df[narrative_columns + coars_columns] = df.apply(process_outcome_and_output, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two distinct dataframes: \n",
    "mask = df['section'].eq('Outcome Statement') \n",
    "# 1. **df_coars**: with Final approved COAR's sections\n",
    "df_coars = df[~mask][general_columns + coars_columns].copy()\n",
    "df_coars.drop_duplicates(inplace=True)\n",
    "df_coars = df_coars[df_coars['section'] != 'NarrativeTitle'].copy()\n",
    "# 2. **df_narrative**: With Outcome and Output individual statements\n",
    "to_keep = general_columns + narrative_columns + description_columns + indicator_columns\n",
    "df_narrative = df[mask][to_keep].copy()\n",
    "df_narrative.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the new column 'Output Analytical Statement of Progress'\n",
    "df_narrative['headline_statement'] = df_narrative['Progress_headline_statement3'].fillna(df_narrative['Progress_headline_statement4'])\n",
    "df_narrative['output_analytical_statement_of_progress'] = df_narrative[indicator_columns].bfill(axis=1).iloc[:, 0]\n",
    "df_narrative['lessons_learned_and_innovations'] = df_narrative['Require_adjustments5'].fillna(df_narrative['Require_adjustments4'])\n",
    "df_narrative['contributions'] = df_narrative['Details_of_Contribution_Test5'].fillna(df_narrative['Details_of_Contribution_Test4'])\n",
    "df_narrative['partnerhsips'] = df_narrative['Partnerhsips5'].fillna(df_narrative['Partnerhsips4'])\n",
    "\n",
    "new_description_columns = ['headline_statement', \n",
    "                           'output_analytical_statement_of_progress',\n",
    "                           'lessons_learned_and_innovations',\n",
    "                           'contributions',\n",
    "                           'partnerhsips']\n",
    "new_narrative_columns = general_columns+narrative_columns + new_description_columns\n",
    "\n",
    "df_narrative = df_narrative[new_narrative_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to aggregate non-empty, non-NaN values into a list\n",
    "def aggregate_non_nan(values):\n",
    "    # Filter out NaN and empty values\n",
    "    filtered_values = [value for value in values if pd.notna(value) and value != '']\n",
    "    return filtered_values[0] if len(filtered_values) > 0 else np.nan  # Return NaN if list is empty\n",
    "\n",
    "# Perform the groupby and aggregation\n",
    "df_narrative = df_narrative.groupby(general_columns + narrative_columns).agg(\n",
    "    {col: aggregate_non_nan for col in new_description_columns}\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_narrative.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = Path(product['data'])\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)  # Create missing directories\n",
    "df_narrative.to_excel(product['data'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unicef-ecaro-cpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
